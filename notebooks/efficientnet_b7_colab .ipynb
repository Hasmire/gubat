{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2nvycKSvTmFw"
      },
      "source": [
        "# Mounting dataset from gdrive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "o3e-i-KLTCwo",
        "outputId": "78e747a8-bde5-4779-b647-df3e1a9f7a6f"
      },
      "outputs": [
        {
          "ename": "ValueError",
          "evalue": "mount failed",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-b53ef65c656e>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Replace 'path/to/your/dataset' with the actual path to your dataset on Google Drive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mdataset_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'/content/drive/My Drive/input/forestnet'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36mmount\u001b[0;34m(mountpoint, force_remount, timeout_ms, readonly)\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_ms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m120000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreadonly\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m   \u001b[0;34m\"\"\"Mount your Google Drive at the specified mountpoint path.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m   return _mount(\n\u001b[0m\u001b[1;32m    101\u001b[0m       \u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m       \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mforce_remount\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36m_mount\u001b[0;34m(mountpoint, force_remount, timeout_ms, ephemeral, readonly)\u001b[0m\n\u001b[1;32m    281\u001b[0m             \u001b[0;34m'https://research.google.com/colaboratory/faq.html#drive-timeout'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    282\u001b[0m         )\n\u001b[0;32m--> 283\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'mount failed'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mextra_reason\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    284\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mcase\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    285\u001b[0m       \u001b[0;31m# Terminate the DriveFS binary before killing bash.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: mount failed"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "dataset_path = '/content/drive/My Drive/input/forestnet'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IuRDHVRcTqpl"
      },
      "source": [
        "# Importing packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "CdkcPYPuTXhN"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import pickle\n",
        "import skimage.draw as sk\n",
        "from fastai.vision.all import *\n",
        "from fastai.imports import *"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8EfrJHkVTvW2"
      },
      "source": [
        "# Read data and create DataFrames"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "9WyHG_OETkm0"
      },
      "outputs": [],
      "source": [
        "train = pd.read_csv('/content/drive/My Drive/input/forestnet/ForestNetDataset/train.csv')\n",
        "val = pd.read_csv('/content/drive/My Drive/input/forestnet/ForestNetDataset/val.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "eBqLd43mT-Eu"
      },
      "outputs": [],
      "source": [
        "train.drop(columns = ['label','latitude','longitude','year'], inplace = True)\n",
        "val.drop(columns = ['label','latitude','longitude','year'], inplace = True)\n",
        "train['is_valid'] = False\n",
        "val['is_valid'] = True\n",
        "imgset = pd.concat([train,val],ignore_index = True)\n",
        "imgset.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hxbaMT_kUDSX"
      },
      "source": [
        "\n",
        "\n",
        "create dictionary with our labels and their corresponding pixel value\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "il61jsZQUAlW"
      },
      "outputs": [],
      "source": [
        "codes_dict = {\"Undefined\": 0, \"Plantation\": 1, \"Smallholder agriculture\": 2,\"Other\": 3,\"Grassland shrubland\": 4}\n",
        "codes_dict.values()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wKkFlYKTUHje"
      },
      "source": [
        "# Semantic segmentation data prep"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "ih33P_x3UFMP"
      },
      "outputs": [],
      "source": [
        "def getEdges(polygon):\n",
        "    edge = []\n",
        "    for i in polygon.exterior.coords:\n",
        "        x,y = i\n",
        "        x = np.round(x).astype(int)\n",
        "        y = np.round(y).astype(int)\n",
        "        edge.append((x,y))\n",
        "    return edge"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "kDpvut_iU5a6"
      },
      "outputs": [],
      "source": [
        "def createPILMask(poly, label, codes):\n",
        "    mask = np.zeros((332,332))\n",
        "    if poly.geom_type == 'Polygon':\n",
        "        # Handle single Polygon case\n",
        "        edge = getEdges(poly)\n",
        "        mask = sk.polygon2mask((332,332),edge)\n",
        "    elif poly.geom_type == 'MultiPolygon':\n",
        "        # Handle MultiPolygon case\n",
        "        for polygon in poly.geoms:  # Iterate over individual Polygons\n",
        "            edge = getEdges(polygon)\n",
        "            pmask = sk.polygon2mask((332,332),edge)\n",
        "            mask = np.logical_or(mask,pmask)\n",
        "    else:\n",
        "        print(\"Invalid geometry type encountered.\")\n",
        "    mask = np.where(mask, codes[label], 0).astype(np.uint8)\n",
        "    return Image.fromarray(mask)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "2rTH7NU8UMqc"
      },
      "outputs": [],
      "source": [
        "def labelToInt(label,codes):\n",
        "    for j,i in enumerate(codes):\n",
        "        if (i == label):\n",
        "            return j"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "8BTzG-kJUQD2"
      },
      "outputs": [],
      "source": [
        "def getForestLoss(path):\n",
        "    with open('/content/drive/My Drive/input/forestnet/ForestNetDataset/'+ path +'/forest_loss_region.pkl', 'rb') as f:\n",
        "        return pickle.load(f)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5W2HkcM0USqR"
      },
      "source": [
        "# Find suitable weights for the labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "2f_5h37vURXm"
      },
      "outputs": [],
      "source": [
        "train_count = train.merged_label.value_counts()\n",
        "train_count"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "K7FKQQP8UVo2"
      },
      "outputs": [],
      "source": [
        "val_count = val.merged_label.value_counts()\n",
        "val_count"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "fizgsHiMUYne"
      },
      "outputs": [],
      "source": [
        "norm_train = np.linalg.norm(np.array(train_count.values))\n",
        "norm_val = np.linalg.norm(np.array(val_count.values))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "axpKHGndUaG4"
      },
      "outputs": [],
      "source": [
        "norm_val = np.linalg.norm(np.array(val_count.values))\n",
        "\n",
        "n_1 = ((train_count / norm_train).values)\n",
        "n_2 = ((val_count / norm_val).values)\n",
        "weights = (n_1 + n_2) / 2\n",
        "# Assign a weight of zero to the \"Undefined\" label.\n",
        "weights = np.insert(weights[::-1],0,0.0)\n",
        "print(codes_dict.keys())\n",
        "weights\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NHYgjetIUc7H"
      },
      "source": [
        "#Put the data in a DataBlock"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "WFg9Gd0mUb9c"
      },
      "outputs": [],
      "source": [
        "db = DataBlock(blocks = (ImageBlock, MaskBlock(codes = codes_dict)),\n",
        "        splitter = ColSplitter(),\n",
        "        get_x = lambda x: \"/content/drive/My Drive/input/forestnet/ForestNetDataset/\"f'{x[1]}'\"/images/visible/composite.png\",\n",
        "        get_y = lambda x: createPILMask(getForestLoss(x[1]),x[0],codes_dict),\n",
        "        item_tfms=Resize(160,method = 'crop'),\n",
        "        batch_tfms=[Normalize.from_stats(*imagenet_stats)])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "QSEuXA0rUu1J"
      },
      "outputs": [],
      "source": [
        "dls = db.dataloaders(imgset, bs = 4)\n",
        "dls.show_batch(vmin = 0,vmax = 5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fk_EUhnAUy1C"
      },
      "source": [
        "# Learning and training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "nVdvCW5oUvCZ"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from fastai.vision.all import *\n",
        "\n",
        "# Load the FPN-based EfficientNet model from torch.hub\n",
        "model = torch.hub.load(\n",
        "    'AdeelH/pytorch-fpn',\n",
        "    'make_fpn_efficientnet',\n",
        "    name='efficientnet-b8',\n",
        "    pretrained=True,\n",
        "    fpn_type='fpn',\n",
        "    num_classes=5,\n",
        "    fpn_channels=256,\n",
        "    in_channels=3,\n",
        "    out_size=(160, 160)\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "G3MHIlMRVIfm"
      },
      "outputs": [],
      "source": [
        "# Accuracy metric\n",
        "def segmentation_accuracy(preds, targets):\n",
        "    # preds.shape: (batch_size, num_classes, height, width)\n",
        "    # targets.shape: (batch_size, height, width)\n",
        "    mask = targets != 0\n",
        "    return (preds.argmax(dim=1)[mask]==targets[mask]).float().mean()\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    print(\"GPU is available!\")\n",
        "    device = torch.device(\"cuda\")\n",
        "else:\n",
        "    print(\"GPU is not available. Using CPU.\")\n",
        "    device = torch.device(\"cpu\")\n",
        "\n",
        "# Modify your Learner code to use the correct device\n",
        "learn = Learner(\n",
        "    dls,\n",
        "    model,\n",
        "    metrics=lambda inp, targ: segmentation_accuracy(inp, targ),\n",
        "    loss_func=LabelSmoothingCrossEntropyFlat(axis=1, weight=tensor(weights).to(device))\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "-ek5sIexVP9V",
        "outputId": "f6d4322b-9317-41ac-b31f-03a7a49988ed"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "<style>\n",
              "    /* Turns off some styling */\n",
              "    progress {\n",
              "        /* gets rid of default border in Firefox and Opera. */\n",
              "        border: none;\n",
              "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "        background-size: auto;\n",
              "    }\n",
              "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
              "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
              "    }\n",
              "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "        background: #F44336;\n",
              "    }\n",
              "</style>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th><lambda></th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>13.120321</td>\n",
              "      <td>36.331982</td>\n",
              "      <td>0.568086</td>\n",
              "      <td>53:21</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-20-874dbf558caa>:3: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
            "  get_x = lambda x: \"/content/drive/My Drive/input/forestnet/ForestNetDataset/\"f'{x[1]}'\"/images/visible/composite.png\",\n",
            "<ipython-input-20-874dbf558caa>:3: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
            "  get_x = lambda x: \"/content/drive/My Drive/input/forestnet/ForestNetDataset/\"f'{x[1]}'\"/images/visible/composite.png\",\n",
            "<ipython-input-20-874dbf558caa>:4: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
            "  get_y = lambda x: createPILMask(getForestLoss(x[1]),x[0],codes_dict),\n",
            "<ipython-input-20-874dbf558caa>:4: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
            "  get_y = lambda x: createPILMask(getForestLoss(x[1]),x[0],codes_dict),\n",
            "<ipython-input-15-0f57279cd652>:3: UserWarning: Unpickling a shapely <2.0 geometry object. Please save the pickle again; shapely 2.1 will not have this compatibility.\n",
            "  return pickle.load(f)\n",
            "<ipython-input-15-0f57279cd652>:3: UserWarning: Unpickling a shapely <2.0 geometry object. Please save the pickle again; shapely 2.1 will not have this compatibility.\n",
            "  return pickle.load(f)\n",
            "<ipython-input-20-874dbf558caa>:3: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
            "  get_x = lambda x: \"/content/drive/My Drive/input/forestnet/ForestNetDataset/\"f'{x[1]}'\"/images/visible/composite.png\",\n",
            "<ipython-input-20-874dbf558caa>:3: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
            "  get_x = lambda x: \"/content/drive/My Drive/input/forestnet/ForestNetDataset/\"f'{x[1]}'\"/images/visible/composite.png\",\n",
            "<ipython-input-20-874dbf558caa>:4: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
            "  get_y = lambda x: createPILMask(getForestLoss(x[1]),x[0],codes_dict),\n",
            "<ipython-input-20-874dbf558caa>:4: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
            "  get_y = lambda x: createPILMask(getForestLoss(x[1]),x[0],codes_dict),\n",
            "<ipython-input-15-0f57279cd652>:3: UserWarning: Unpickling a shapely <2.0 geometry object. Please save the pickle again; shapely 2.1 will not have this compatibility.\n",
            "  return pickle.load(f)\n",
            "<ipython-input-15-0f57279cd652>:3: UserWarning: Unpickling a shapely <2.0 geometry object. Please save the pickle again; shapely 2.1 will not have this compatibility.\n",
            "  return pickle.load(f)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "<style>\n",
              "    /* Turns off some styling */\n",
              "    progress {\n",
              "        /* gets rid of default border in Firefox and Opera. */\n",
              "        border: none;\n",
              "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "        background-size: auto;\n",
              "    }\n",
              "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
              "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
              "    }\n",
              "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "        background: #F44336;\n",
              "    }\n",
              "</style>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      <progress value='2' class='' max='8' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      25.00% [2/8 1:44:16&lt;5:12:48]\n",
              "    </div>\n",
              "    \n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th><lambda></th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>1.743037</td>\n",
              "      <td>1.906021</td>\n",
              "      <td>0.501880</td>\n",
              "      <td>52:14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>3.154219</td>\n",
              "      <td>17.628099</td>\n",
              "      <td>0.327451</td>\n",
              "      <td>52:01</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>\n",
              "\n",
              "    <div>\n",
              "      <progress value='187' class='' max='404' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      46.29% [187/404 22:24&lt;26:00 2.1992]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-20-874dbf558caa>:3: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
            "  get_x = lambda x: \"/content/drive/My Drive/input/forestnet/ForestNetDataset/\"f'{x[1]}'\"/images/visible/composite.png\",\n",
            "<ipython-input-20-874dbf558caa>:3: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
            "  get_x = lambda x: \"/content/drive/My Drive/input/forestnet/ForestNetDataset/\"f'{x[1]}'\"/images/visible/composite.png\",\n",
            "<ipython-input-20-874dbf558caa>:4: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
            "  get_y = lambda x: createPILMask(getForestLoss(x[1]),x[0],codes_dict),\n",
            "<ipython-input-15-0f57279cd652>:3: UserWarning: Unpickling a shapely <2.0 geometry object. Please save the pickle again; shapely 2.1 will not have this compatibility.\n",
            "  return pickle.load(f)\n",
            "<ipython-input-20-874dbf558caa>:4: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
            "  get_y = lambda x: createPILMask(getForestLoss(x[1]),x[0],codes_dict),\n",
            "<ipython-input-15-0f57279cd652>:3: UserWarning: Unpickling a shapely <2.0 geometry object. Please save the pickle again; shapely 2.1 will not have this compatibility.\n",
            "  return pickle.load(f)\n",
            "<ipython-input-20-874dbf558caa>:3: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
            "  get_x = lambda x: \"/content/drive/My Drive/input/forestnet/ForestNetDataset/\"f'{x[1]}'\"/images/visible/composite.png\",\n",
            "<ipython-input-20-874dbf558caa>:4: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
            "  get_y = lambda x: createPILMask(getForestLoss(x[1]),x[0],codes_dict),\n",
            "<ipython-input-15-0f57279cd652>:3: UserWarning: Unpickling a shapely <2.0 geometry object. Please save the pickle again; shapely 2.1 will not have this compatibility.\n",
            "  return pickle.load(f)\n",
            "<ipython-input-20-874dbf558caa>:3: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
            "  get_x = lambda x: \"/content/drive/My Drive/input/forestnet/ForestNetDataset/\"f'{x[1]}'\"/images/visible/composite.png\",\n",
            "<ipython-input-20-874dbf558caa>:4: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
            "  get_y = lambda x: createPILMask(getForestLoss(x[1]),x[0],codes_dict),\n",
            "<ipython-input-15-0f57279cd652>:3: UserWarning: Unpickling a shapely <2.0 geometry object. Please save the pickle again; shapely 2.1 will not have this compatibility.\n",
            "  return pickle.load(f)\n",
            "<ipython-input-20-874dbf558caa>:3: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
            "  get_x = lambda x: \"/content/drive/My Drive/input/forestnet/ForestNetDataset/\"f'{x[1]}'\"/images/visible/composite.png\",\n",
            "<ipython-input-20-874dbf558caa>:3: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
            "  get_x = lambda x: \"/content/drive/My Drive/input/forestnet/ForestNetDataset/\"f'{x[1]}'\"/images/visible/composite.png\",\n",
            "<ipython-input-20-874dbf558caa>:4: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
            "  get_y = lambda x: createPILMask(getForestLoss(x[1]),x[0],codes_dict),\n",
            "<ipython-input-15-0f57279cd652>:3: UserWarning: Unpickling a shapely <2.0 geometry object. Please save the pickle again; shapely 2.1 will not have this compatibility.\n",
            "  return pickle.load(f)\n",
            "<ipython-input-20-874dbf558caa>:4: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
            "  get_y = lambda x: createPILMask(getForestLoss(x[1]),x[0],codes_dict),\n",
            "<ipython-input-15-0f57279cd652>:3: UserWarning: Unpickling a shapely <2.0 geometry object. Please save the pickle again; shapely 2.1 will not have this compatibility.\n",
            "  return pickle.load(f)\n",
            "<ipython-input-20-874dbf558caa>:3: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
            "  get_x = lambda x: \"/content/drive/My Drive/input/forestnet/ForestNetDataset/\"f'{x[1]}'\"/images/visible/composite.png\",\n",
            "<ipython-input-20-874dbf558caa>:4: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
            "  get_y = lambda x: createPILMask(getForestLoss(x[1]),x[0],codes_dict),\n",
            "<ipython-input-20-874dbf558caa>:3: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
            "  get_x = lambda x: \"/content/drive/My Drive/input/forestnet/ForestNetDataset/\"f'{x[1]}'\"/images/visible/composite.png\",\n",
            "<ipython-input-15-0f57279cd652>:3: UserWarning: Unpickling a shapely <2.0 geometry object. Please save the pickle again; shapely 2.1 will not have this compatibility.\n",
            "  return pickle.load(f)\n",
            "<ipython-input-20-874dbf558caa>:4: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
            "  get_y = lambda x: createPILMask(getForestLoss(x[1]),x[0],codes_dict),\n",
            "<ipython-input-15-0f57279cd652>:3: UserWarning: Unpickling a shapely <2.0 geometry object. Please save the pickle again; shapely 2.1 will not have this compatibility.\n",
            "  return pickle.load(f)\n",
            "<ipython-input-20-874dbf558caa>:3: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
            "  get_x = lambda x: \"/content/drive/My Drive/input/forestnet/ForestNetDataset/\"f'{x[1]}'\"/images/visible/composite.png\",\n",
            "<ipython-input-20-874dbf558caa>:3: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
            "  get_x = lambda x: \"/content/drive/My Drive/input/forestnet/ForestNetDataset/\"f'{x[1]}'\"/images/visible/composite.png\",\n",
            "<ipython-input-20-874dbf558caa>:4: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
            "  get_y = lambda x: createPILMask(getForestLoss(x[1]),x[0],codes_dict),\n",
            "<ipython-input-20-874dbf558caa>:4: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
            "  get_y = lambda x: createPILMask(getForestLoss(x[1]),x[0],codes_dict),\n",
            "<ipython-input-15-0f57279cd652>:3: UserWarning: Unpickling a shapely <2.0 geometry object. Please save the pickle again; shapely 2.1 will not have this compatibility.\n",
            "  return pickle.load(f)\n",
            "<ipython-input-15-0f57279cd652>:3: UserWarning: Unpickling a shapely <2.0 geometry object. Please save the pickle again; shapely 2.1 will not have this compatibility.\n",
            "  return pickle.load(f)\n"
          ]
        }
      ],
      "source": [
        "learn.fine_tune(8)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "LCNjCJYStx7H"
      },
      "outputs": [],
      "source": [
        "preds = learn.get_preds()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "gqP41cjbt_XB"
      },
      "outputs": [],
      "source": [
        "preds[0].shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "Uy4EeDu4wqN7"
      },
      "outputs": [],
      "source": [
        "preds[0][0][0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "iX-OTD15zQ_i"
      },
      "outputs": [],
      "source": [
        "predicted_classes = torch.argmax(preds[0], dim=1)\n",
        "predicted_classes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "_CfGWTDXxa4U"
      },
      "outputs": [],
      "source": [
        "# Assuming 'preds' is your tensor\n",
        "max_value = torch.max(preds[0])\n",
        "print(max_value)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "AhoU6iJTlc1B"
      },
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "\n",
        "torch.save(learn.model.state_dict(), '/content/drive/MyDrive/efficientnet.pth')\n",
        "files.download('/content/drive/MyDrive/efficientnet.pth')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I_Ta_WSqvySa"
      },
      "source": [
        "# Validation Accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "aJ95TVylv4zn"
      },
      "outputs": [],
      "source": [
        "predicted_classes = torch.argmax(preds[0], dim=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Et_QCKIf64Mo"
      },
      "source": [
        "### Getting the validation accuracy of each class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "wxgYnH3Q3E_o"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "\n",
        "codes_dict = {\"Undefined\": 0, \"Plantation\": 1, \"Smallholder agriculture\": 2,\"Other\": 3,\"Grassland shrubland\": 4}\n",
        "\n",
        "class_correct = {label: 0 for label in codes_dict.keys()}\n",
        "class_total = {label: 0 for label in codes_dict.keys()}\n",
        "\n",
        "\n",
        "for i in range(predicted_classes.shape[0]):\n",
        "    # Flatten the tensor for the current image\n",
        "    flattened_predictions = predicted_classes[i].flatten()\n",
        "\n",
        "    # Calculate the mode (most frequent element) for the current image\n",
        "    predicted_label, count = torch.mode(flattened_predictions)\n",
        "\n",
        "    # Get the label name from the dictionary\n",
        "    predicted_label_name = [key for key, value in codes_dict.items() if value == predicted_label.item()][0]\n",
        "\n",
        "    # Get the actual label from the DataFrame\n",
        "    actual_label = val['merged_label'].iloc[i]\n",
        "\n",
        "    # print(f\"Image {i+1}: Predicted: {predicted_label_name}, Actual: {actual_label}\")\n",
        "\n",
        "    class_total[actual_label] += 1\n",
        "    if predicted_label_name == actual_label:\n",
        "        class_correct[actual_label] += 1\n",
        "\n",
        "for label in codes_dict.keys():\n",
        "    accuracy = 100 * class_correct[label] / class_total[label] if class_total[label] > 0 else 0\n",
        "    print(f\"Accuracy of {label}: {accuracy:.2f}%\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Getting validation macro accuracy"
      ],
      "metadata": {
        "id": "ROtlC26dp8hH"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "2mpGD0fh4q77"
      },
      "outputs": [],
      "source": [
        "# Calculate macro accuracy\n",
        "total_correct = sum(class_correct.values())\n",
        "total_samples = sum(class_total.values())\n",
        "macro_accuracy = 100 * total_correct / total_samples\n",
        "\n",
        "print(f\"Macro Accuracy: {macro_accuracy:.2f}%\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Getting validation macro f1"
      ],
      "metadata": {
        "id": "4jEcelLvp_ve"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import f1_score\n",
        "\n",
        "# Assuming 'preds' contains your model's predictions and 'val' is your DataFrame\n",
        "predicted_classes = torch.argmax(preds[0], dim=1)\n",
        "\n",
        "# Flatten the predictions and extract true labels\n",
        "y_true = val['merged_label'].tolist()  # Assuming 'merged_label' column holds the true labels\n",
        "y_pred = []\n",
        "for i in range(predicted_classes.shape[0]):\n",
        "    flattened_predictions = predicted_classes[i].flatten()\n",
        "    predicted_label, _ = torch.mode(flattened_predictions)\n",
        "    predicted_label_name = [key for key, value in codes_dict.items() if value == predicted_label.item()][0]\n",
        "    y_pred.append(predicted_label_name)\n",
        "\n",
        "# Calculate the macro F1-score\n",
        "f1_macro = f1_score(y_true, y_pred, average='macro')\n",
        "print(f\"Macro F1-score: {f1_macro:.2f}\")\n"
      ],
      "metadata": {
        "id": "TcNs9xGgpayC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Visualizing predictions"
      ],
      "metadata": {
        "id": "Oh9v8CuZqCNU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vset = imgset[imgset.is_valid == True]\n",
        "vset.reset_index(drop = True, inplace = True)\n"
      ],
      "metadata": {
        "id": "p9BYjnifpkPt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import scipy.stats\n",
        "\n",
        "def label_predict(target,pred,codes,test):\n",
        "    maskindices = np.nonzero(target)\n",
        "    if test:\n",
        "        maskindices = zip(maskindices[0],maskindices[1])\n",
        "    pred_labels = pred.argmax(dim = 0)\n",
        "    label_vals = [pred_labels[i[0]][i[1]].item() for i in maskindices]\n",
        "    mode_result = scipy.stats.mode(label_vals)\n",
        "    # Check if the mode is a scalar and handle it accordingly\n",
        "    mode_value = mode_result.mode if isinstance(mode_result.mode, np.ndarray) else mode_result.mode.item()\n",
        "    return list(codes)[mode_value]\n",
        "\n",
        "  def predict_mask(target,pred,test):\n",
        "    maskindices = np.nonzero(target)\n",
        "    if test:\n",
        "        maskindices = zip(maskindices[0],maskindices[1])\n",
        "    pred_labels = pred.argmax(dim = 0)\n",
        "    p_mask = np.zeros(target.shape)\n",
        "    for i in maskindices:\n",
        "        p_mask[i[0]][i[1]] = pred_labels[i[0]][i[1]].item()\n",
        "    f, ax = plt.subplots(1,2,figsize=(20, 10))\n",
        "    ax[0].imshow(target)\n",
        "    ax[1].imshow(p_mask)\n",
        "    ax[0].set_title(\"ground truth\")\n",
        "    ax[1].set_title(\"prediction\")\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "id": "fQNS6PVPpoUC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predict_mask(preds[1][2],preds[0][2],False)\n",
        "p = label_predict(preds[1][2],preds[0][2],codes_dict,False)\n",
        "g = vset.iloc[1][0]\n",
        "print(\"predicted label: \", p)\n",
        "print(\"correct label: \", g)"
      ],
      "metadata": {
        "id": "YIHbupnApoRu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i, j in enumerate(vset.head(10).values):\n",
        "    f, ax = plt.subplots(1,2,figsize=(20, 10))\n",
        "    im = PILImage.create(\"/content/drive/My Drive/input/forestnet/ForestNetDataset/\"f'{j[1]}'\"/images/visible/composite.png\")\n",
        "    ax[0].imshow(im)\n",
        "    ax[1].imshow(preds[0][i].argmax(dim = 0))\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "id": "4Zu_ECyKpoPd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Examine Model Performance on test data"
      ],
      "metadata": {
        "id": "EE4_shi0qGMj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Test accuracy"
      ],
      "metadata": {
        "id": "gamlDKkdqI6X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test = pd.read_csv('/content/drive/My Drive/input/forestnet/ForestNetDataset/test.csv')\n",
        "test.drop(columns = ['label','latitude','longitude','year'], inplace = True)"
      ],
      "metadata": {
        "id": "VUKV4c0GpoNB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def t_acc(df,codes):\n",
        "#     undefined_count = 0\n",
        "    acc = []\n",
        "    label = df.iloc[0][0]\n",
        "    for x in df.values:\n",
        "        im = PILImage.create(\"/content/drive/My Drive/input/forestnet/ForestNetDataset/\"f'{x[1]}'\"/images/visible/composite.png\")\n",
        "        AOI = createPILMask(getForestLoss(x[1]),x[0],codes)\n",
        "        p = learn.predict(im)\n",
        "        acc.append(label_predict(AOI.crop_pad(p[2].shape[1]),p[2],codes,True))\n",
        "#     print(len([x for x in acc if \"Undefined\" in x]))\n",
        "    return (len([x for x in acc if label in x]) / len(acc))\n"
      ],
      "metadata": {
        "id": "f8nXrfg3poKb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "t_plant = test[test.merged_label == 'Plantation']\n",
        "t_other = test[test.merged_label == 'Other']\n",
        "t_grass = test[test.merged_label == 'Grassland shrubland']\n",
        "t_small = test[test.merged_label == 'Smallholder agriculture']\n",
        "\n",
        "plantation = t_acc(t_plant,codes_dict)\n",
        "other = t_acc(t_other,codes_dict)\n",
        "grass = t_acc(t_grass,codes_dict)\n",
        "small = t_acc(t_small,codes_dict)\n"
      ],
      "metadata": {
        "id": "mhwup9ZxpoIe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('plantation accuracy: ', np.around(plantation,4))\n",
        "print('other accuracy: ', np.around(other,4))\n",
        "print('grassland shrubland accuracy: ', np.around(grass,4))\n",
        "print('smallholder agriculture accuracy: ', np.around(small,4))"
      ],
      "metadata": {
        "id": "So1u5VsWpoF-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Macro F1 and Macro Accuracy"
      ],
      "metadata": {
        "id": "OC_D6qtvqLRm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "def t_acc_macro(df, codes):\n",
        "    y_true = df.iloc[:, 0].tolist()  # Extract true labels\n",
        "    y_pred = []\n",
        "    for x in df.values:\n",
        "        im = PILImage.create(\"/content/drive/My Drive/input/forestnet/ForestNetDataset/\"f'{x[1]}'\"/images/visible/composite.png\")\n",
        "        AOI = createPILMask(getForestLoss(x[1]), x[0], codes)\n",
        "        p = learn.predict(im)\n",
        "        y_pred.append(label_predict(AOI.crop_pad(p[2].shape[1]), p[2], codes, True))\n",
        "\n",
        "    # Calculate macro accuracy using accuracy_score\n",
        "    macro_accuracy = accuracy_score(y_true, y_pred)\n",
        "    print(f\"Macro Accuracy: {macro_accuracy:.4f}\")\n",
        "\n",
        "    return macro_accuracy\n",
        "\n",
        "\n",
        "def t_f1_macro(df,codes):\n",
        "    y_true = df.iloc[:,0].tolist()\n",
        "    y_pred = []\n",
        "    for x in df.values:\n",
        "        im = PILImage.create(\"/content/drive/My Drive/input/forestnet/ForestNetDataset/\"f'{x[1]}'\"/images/visible/composite.png\")\n",
        "        AOI = createPILMask(getForestLoss(x[1]),x[0],codes)\n",
        "        p = learn.predict(im)\n",
        "        y_pred.append(label_predict(AOI.crop_pad(p[2].shape[1]),p[2],codes,True))\n",
        "    return f1_score(y_true, y_pred, average='macro')"
      ],
      "metadata": {
        "id": "VPrOatBbpoDo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "macro_acc = t_acc_macro(test,codes_dict)\n",
        "print('test macro accuracy: ', np.around(macro_acc,4))"
      ],
      "metadata": {
        "id": "L8ps3myd2h0e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "macro_f1 = t_f1_macro(test,codes_dict)\n",
        "print('test macro f1: ', np.around(macro_f1,4))\n"
      ],
      "metadata": {
        "id": "3NkTOZYC2jkd"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}